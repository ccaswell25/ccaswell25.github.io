[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "More details to come!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "More details to come!"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Carly Caswell",
    "section": "",
    "text": "--- title: “Projects”\n---"
  },
  {
    "objectID": "posts/2023-12-06 python/eds220-finalblog.html",
    "href": "posts/2023-12-06 python/eds220-finalblog.html",
    "title": "Analyzing Santa Barbara County’s Thomas Fire",
    "section": "",
    "text": "Project Repository: https://github.com/ccaswell25/eds220-hwk4-task3"
  },
  {
    "objectID": "posts/2023-12-06 python/eds220-finalblog.html#about-this-project",
    "href": "posts/2023-12-06 python/eds220-finalblog.html#about-this-project",
    "title": "Analyzing Santa Barbara County’s Thomas Fire",
    "section": "About this Project",
    "text": "About this Project\n-add details about the thomas fire and what i’m intending to do- I will create a false color image to show the location of the Thomas fire in 2017 and the impact of air quality on that specific area during the time period of the fire.\n-add a thomas fire picture with caption-\n\nAnalysis Highlights:\n-Geospatial data exploration\n-Data wrangling and manipulation of raster and tabular data\n-Data analysis calculate moving averages for air quality index during the period of the Thomas Fire (2017)\n-Creating and customizing a map of the Thomas Fire burn area and AQI moving averages from 2017-2018\n\n\nAbout the Data:\nDataset 1\nA simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data, collected by the Landsat 8 satellite.\nInformation about Landsat bands from USGS:\nWhat are the band designations for the Landsat satellites?\nCommon Landsat Band Combinations\nHow do I use a scale factor with Landsat Level-2 science products?\nThe data was accessed and pre-processed in the Microsoft Planetary Computer to remove data outside land and coarsen the spatial resolution (Landsat Collection in MPC). Data should be used for visualization purposes only.\nDataset 2\nA shapefile of fire perimeters in California during 2017. The complete file can be accessed in the CA state geoportal.\nDataset 3\nWe are using Air Quality Index (AQI) data from the US Environmental Protection Agency to visualize the impact on the AQI of the 2017 Thomas Fire in Santa Barbara County."
  },
  {
    "objectID": "posts/2023-12-06 python/eds220-finalblog.html#importing",
    "href": "posts/2023-12-06 python/eds220-finalblog.html#importing",
    "title": "Analyzing Santa Barbara County’s Thomas Fire",
    "section": "Importing",
    "text": "Importing\n\n\nCode\n#Importing Libraries I Will Need\nimport os\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport xarray as xr\nimport pandas as pd \nfrom shapely.geometry import Polygon \nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Patch\nfrom shapely.geometry import Point\nimport matplotlib.lines as mlines\n\n\n\n\nCode\n# Importing Data\n#Reading in bands data \nbands = os.path.join(os.getcwd(), 'data', 'landsat8-2018-01-26-sb-simplified.nc') \nbands = rioxr.open_rasterio(bands)\n\n#Reading in CA fires data \nca_fires = gpd.read_file(os.path.join(os.getcwd(), 'data', 'California_Fire_Perimeters_2017.shp'))\n\n#Reading in AQI data for 2017 and 2018\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\")\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\")"
  },
  {
    "objectID": "posts/2023-12-06 python/eds220-finalblog.html#calculating-the-rolling-averages",
    "href": "posts/2023-12-06 python/eds220-finalblog.html#calculating-the-rolling-averages",
    "title": "Analyzing Santa Barbara County’s Thomas Fire",
    "section": "Calculating the Rolling Averages",
    "text": "Calculating the Rolling Averages\nWe want to evaluate the change in air quality from before, during, and after the fire in 2017 and 2018. To do this, we need to calculate a 5 day rolling average of the air quality index data. To do this, we first need to make sure we are only looking at Santa Barbara County data, combine our 2017 and 2018 data, and clean up any fields necessary. Then we can calculate moving averages and plot the data to evaluate any impacts of the Thomas Fire on Santa Barbara County.\n\n\nCode\n# Selecting only data from 'Santa Barbara' county\naqi_sb = aqi[aqi['county_name'] == 'Santa Barbara'].copy()\n\n# Dropping columns we don't need\ncolumns_to_drop = ['state_name', 'county_name', 'state_code', 'county_code']\naqi_sb.drop(columns_to_drop, inplace=True, axis = 1)\n\n# Updating the date column to a datetime object\naqi_sb['date'] = pd.to_datetime(aqi_sb['date'])\n\n# Setting the index to be the date column\naqi_sb.set_index('date', inplace=True)\n\n# Calculating the rolling window for the AQI_SB data:\naqi_sb.aqi.rolling('5D').mean()\n\n# Adding a new column with the 5-day rolling mean:\naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean()\n\n#Now we can plot the rolling averages! \nplt.figure(figsize=(12, 6))\nplt.plot(aqi_sb.index, aqi_sb['aqi'], label='Daily AQI', color='cornflowerblue')\nplt.plot(aqi_sb.index, aqi_sb['five_day_average'], label='5-Day Average', color='salmon')\nplt.title('AQI and 5-Day Average')\nplt.xlabel('Date')\nplt.ylabel('AQI')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/2023-12-06 python/eds220-finalblog.html#creating-a-false-image-of-the-california-thomas-fire-burn-area",
    "href": "posts/2023-12-06 python/eds220-finalblog.html#creating-a-false-image-of-the-california-thomas-fire-burn-area",
    "title": "Analyzing Santa Barbara County’s Thomas Fire",
    "section": "Creating a False Image of the California Thomas Fire Burn Area",
    "text": "Creating a False Image of the California Thomas Fire Burn Area\nWe want to evaluate the change in air quality from before, during, and after the fire in 2017 and 2018. To do this, we need to calculate a 5 day rolling average of the air quality index data. To do this, we first need to make sure we are only looking at Santa Barbara County data, combine our 2017 and 2018 data, and clean up any fields necessary. Then we can calculate moving averages and plot the data to evaluate any impacts of the Thomas Fire on Santa Barbara County.\n\n\nCode\n# Making sure I have just the Thomas Fire data:\nca_fires_new = ca_fires[ca_fires.fire_name == \"THOMAS\"]\n\n# Updating the CRS's:\nprint(ca_fires.crs)\nprint(bands.rio.crs)\n#I noticed they are different so I'm going to convert the CA crs\nca_fires_new = ca_fires_new.to_crs(32611)\n\n#checking to make sure the crs is updated:\nca_fires_new.crs == bands.rio.crs\n\n#Creating a false color image \nbands[[\"swir22\", \"nir08\", \"red\"]].to_array()\n#Now we have our image we can graph this with our Thomas Fire perimeter\n\n\n# Now we can plot!\nfig, ax = plt.subplots()\nsize = 6 #height in of plot \naspect = bands.rio.width/bands.rio.height\nfig.set_size_inches(size, size*aspect) #why? bc cannot use ax and size aspect together\nbands[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(ax=ax, robust = True)\nca_fires_new .plot(ax=ax,facecolor='none', edgecolor='red', linewidth=2, alpha=0.5)\n\n## Set plot title\nplt.title('Map of the Thomas Fire Perimeter (2017) in California')\n\n# Remove the axes\nplt.axis('off')\n\n# Set legend with linestyle='None'\nlegend_elements = [mlines.Line2D([0], [0], color='red', marker = '_', linestyle='None', markersize=10, label='Thomas Fire')]\n\n# Add legend\nax.legend(handles=legend_elements)\n\n## Showing the plot\nplt.show()"
  },
  {
    "objectID": "posts/2023-12-06 python/eds242-finalblog.html",
    "href": "posts/2023-12-06 python/eds242-finalblog.html",
    "title": "Analyzing the Implications of Data, Documentation, and Decision-Making in Climate-Driven Artificial Intelligence",
    "section": "",
    "text": "Artificial Intelligence (AI) stands out as a prevailing buzzword of this era. It is everywhere we live, work, and interact - from the advertisements on our screens to the technology in our homes and in integral services like those provided by banks, airports, and hospitals. At the basis of AI is algorithms, a systematic set of instructions or rules used to solve problems. Focusing on efforts related to climate work, algorithm application can be applied to predicting temperature changes, weather events, future deforestation, and carbon emissions. It can be used to show the effects of extreme weather, potential benefits of carbon capture and regenerative agriculture, and even nudge the general public to pursue climate-friendly ways of changing habits and behaviors (Coeckelbergh).\nAlgorithms, however, can lead to biased decision-making. There is plenty of evidence that exists to prove biases in algorithms, including research on algorithms detecting skin cancer that was only effective on light skin tones because of a non-demographically diverse dataset (Calderon) or Amazon’s hiring algorithm exhibiting gender bias when designed to review job applicants, favoring male candidates over female candidates because the training data reflected a male-dominated workforce (Dastin). Algorithmic-generated content needs to be critiqued and reviewed through the lens of auditing. Algorithmic auditing is a crucial way to address the challenges associated with the increasing use of algorithms and dependence of them on our decision-making. In order to audit algorithms effectively, we need to question the basis of AI before allowing it to drive our human-based decisions (whether we consider AI to be “moral” decision-making is a whole other topic that I won’t get into today). When considering environmentally-focused algorithmic decision-making, I think it’s crucial to contemplate three aspects of algorithm creation: Data, Documentation, and Decision-makers (3Ds)."
  },
  {
    "objectID": "posts/2023-12-06 python/eds242-finalblog.html#the-three-ds-analyzing-the-implications-of-data-documentation-and-decision-making-in-climate-driven-artificial-intelligence",
    "href": "posts/2023-12-06 python/eds242-finalblog.html#the-three-ds-analyzing-the-implications-of-data-documentation-and-decision-making-in-climate-driven-artificial-intelligence",
    "title": "Analyzing the Implications of Data, Documentation, and Decision-Making in Climate-Driven Artificial Intelligence",
    "section": "",
    "text": "Artificial Intelligence (AI) stands out as a prevailing buzzword of this era. It is everywhere we live, work, and interact - from the advertisements on our screens to the technology in our homes and in integral services like those provided by banks, airports, and hospitals. At the basis of AI is algorithms, a systematic set of instructions or rules used to solve problems. Focusing on efforts related to climate work, algorithm application can be applied to predicting temperature changes, weather events, future deforestation, and carbon emissions. It can be used to show the effects of extreme weather, potential benefits of carbon capture and regenerative agriculture, and even nudge the general public to pursue climate-friendly ways of changing habits and behaviors (Coeckelbergh).\nAlgorithms, however, can lead to biased decision-making. There is plenty of evidence that exists to prove biases in algorithms, including research on algorithms detecting skin cancer that was only effective on light skin tones because of a non-demographically diverse dataset (Calderon) or Amazon’s hiring algorithm exhibiting gender bias when designed to review job applicants, favoring male candidates over female candidates because the training data reflected a male-dominated workforce (Dastin). Algorithmic-generated content needs to be critiqued and reviewed through the lens of auditing. Algorithmic auditing is a crucial way to address the challenges associated with the increasing use of algorithms and dependence of them on our decision-making. In order to audit algorithms effectively, we need to question the basis of AI before allowing it to drive our human-based decisions (whether we consider AI to be “moral” decision-making is a whole other topic that I won’t get into today). When considering environmentally-focused algorithmic decision-making, I think it’s crucial to contemplate three aspects of algorithm creation: Data, Documentation, and Decision-makers (3Ds)."
  },
  {
    "objectID": "posts/2023-12-06 python/eds242-finalblog.html#data-weve-got-a-problem",
    "href": "posts/2023-12-06 python/eds242-finalblog.html#data-weve-got-a-problem",
    "title": "Analyzing the Implications of Data, Documentation, and Decision-Making in Climate-Driven Artificial Intelligence",
    "section": "Data, We’ve Got a Problem",
    "text": "Data, We’ve Got a Problem\nAs a Data Scientist, I interact with new and evolving datasets just about every day. This data is sourced from a variety of topics and contributors, and in the work that I do, I’ve been taught to take a deeper look, ask questions, and consider the biases that went into the data. According to Jennifer Logg, an Assistant Professor of Management at Georgetown University, “….algorithms can efficiently compound bias that is present in the input data. An algorithm will magnify any patterns in the input data, so if bias is present, the algorithm will also magnify that bias, “(Rock). Climate justice relies heavily on accurate data representation to inform policies and decision-making processes. When biased data becomes the inputs to algorithms that shape these decisions, it can result in disproportionate impacts on marginalized communities. If these biases are not properly addressed during algorithmic analysis, it can lead to the reinforcement of existing disparities. For example, an algorithm that relies on biased pollution data might misallocate resources in its decision-making, leaving already vulnerable communities without protection. To achieve environmental justice in AI-driven climate work, we need to acknowledge, scrutinize, and correct biases in the data used by algorithms. By prioritizing fairness in data analysis, we can build algorithms that contribute to equitable environmental decisions, policies, and practices."
  },
  {
    "objectID": "posts/2023-12-06 python/eds242-finalblog.html#document-document-document",
    "href": "posts/2023-12-06 python/eds242-finalblog.html#document-document-document",
    "title": "Analyzing the Implications of Data, Documentation, and Decision-Making in Climate-Driven Artificial Intelligence",
    "section": "Document! Document! Document!",
    "text": "Document! Document! Document!\nSimilar to the creation of datasheets for datasets, algorithm-driven decisions need to have documentation formulating the inner workings of the algorithm, including its design, logic, and decision-making processes. This transparency can allow auditors and stakeholders to understand how the algorithm operates, which is essential for assessing its fairness, accuracy, and potential biases. I believe documentation in the form of some sort of watermarking system, could allow users to have transparency and future trust in the algorithms they are interacting with. Thorough documentation, in general, contributes to better transparency, reproducibility, and accountability of algorithmic systems, making the auditing process more effective and reliable. With watermarking systems, we can ensure that auditors have “checked” off the necessary information for assessing an algorithm’s performance, and if unable to watermark for approval, could identify potential issues, and make informed recommendations for improvement."
  },
  {
    "objectID": "posts/2023-12-06 python/eds242-finalblog.html#who-decides",
    "href": "posts/2023-12-06 python/eds242-finalblog.html#who-decides",
    "title": "Analyzing the Implications of Data, Documentation, and Decision-Making in Climate-Driven Artificial Intelligence",
    "section": "Who Decides?",
    "text": "Who Decides?\nEffective auditing (as well as creation) of algorithms is reliant on informed decision-makers who understand the nuances of ethical data and decision-making. As Coecklebergh states in AI for Climate, “….those who develop and use AI have a special (in the sense of “specific”) responsibility. To make sure that AI leads to a greener and more climate friendly world is definitely also the responsibility of computer scientists, engineers, designers, managers, investors, and others involved in, managing, and promoting, AI and data science practices,” (Coeckelbergh). We also need to bring to the table decision-makers that are going to make fair decisions and keep the general public in mind. Consider Google’s recent creation of their Advanced Technology Ethics Advisory council, which aimed to advise on the company’s usage of AI. “….they were not transparent about their roles, responsibilities, and authority. Rather than engage affected communities, Google appointed a Council member who opposed LGBT rights. Google’s approach to oversight fostered distrust and protests, and the Council was dissolved,” (Calderon). In my opinion, human intervention will always be needed to create checks and balances with any form of AI that is driving our decisions, behaviors, and analyses. In the realm of climate justice, where algorithmic systems can impact something like policy formation, knowledgeable, fair, and adequately represented decision-makers are crucial to the formation and usage of AI in climate work."
  },
  {
    "objectID": "posts/2023-12-06 python/eds242-finalblog.html#ai-dont-worry-we-still-love-you",
    "href": "posts/2023-12-06 python/eds242-finalblog.html#ai-dont-worry-we-still-love-you",
    "title": "Analyzing the Implications of Data, Documentation, and Decision-Making in Climate-Driven Artificial Intelligence",
    "section": "AI, Don’t Worry We Still Love You",
    "text": "AI, Don’t Worry We Still Love You\nTo conclude, in order to promote ethical data usage and responsible AI application we must safeguard future use of AI in environmental justice by taking a fine-tooth comb to the 3Ds (Data, Documentation, and Decision-makers). As Jennifer Logg so eloquently stated, “Trashing the mirror does not heal the bruise, but it could prolong the time it takes to fix the problem and detect future ones,”(Rock). In an era where algorithms increasingly influence critical aspects of our lives, of indigenous communities, of nature, and of our planet, we need to ensure these rapidly emerging systems undergo rigorous scrutiny and auditing. If we implement the three D’s to algorithm creation and usage, and even consider a “stamp of approval”, we can have some level of a “digital signature”, attesting to the legitimacy and ethical compliance of the underlying processes. This stamp of approval could then be implemented in policies and compliance for future creation and usage of AI in not just climate application, but any field."
  },
  {
    "objectID": "posts/2023-12-06 python/eds242-finalblog.html#sources",
    "href": "posts/2023-12-06 python/eds242-finalblog.html#sources",
    "title": "Analyzing the Implications of Data, Documentation, and Decision-Making in Climate-Driven Artificial Intelligence",
    "section": "Sources:",
    "text": "Sources:\nCalderon, A., Taber, D., Qu, H., Wen, J., et al. (2019). AI Blindspot Cards. Retrieved from www.aiblindspot.com (Version 1.1).\nCoeckelbergh, M. (2020). “AI for climate: freedom, justice, and other ethical and political challenges.” AI and Ethics, Pg 1-6.\nDastin, J. (2018, October 10). Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. Retrieved from https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G\nRock, D., Whittlestone, J., & Garrett, N. (2019, August 7). Using Algorithms to Understand the Biases in Your Organization. Harvard Business Review. Retrieved from https://hbr.org/2019/08/using-algorithms-to-understand-the-biases-in-your-organization\n​​Smith, J. (2022, March 15). How AI Can Help Tackle Climate Change. Techopedia, https://www.techopedia.com/how-ai-can-help-tackle-climate-change/2/33622"
  },
  {
    "objectID": "posts/2023-10-29-short-post-description/index.html",
    "href": "posts/2023-10-29-short-post-description/index.html",
    "title": "test blog post title",
    "section": "",
    "text": "I am going to insert a footnote here1."
  },
  {
    "objectID": "posts/2023-10-29-short-post-description/index.html#footnotes",
    "href": "posts/2023-10-29-short-post-description/index.html#footnotes",
    "title": "test blog post title",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere is the associated footnote, which will appear at the bottom of my document in a “Footnotes” section.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carly Caswell",
    "section": "",
    "text": "My name is Carly and welcome to my personal website. This site will give you an overview of my professional life, interests, and passions (both personal and work-related).\nWhat am I up to right now?\nI am currently a Master of Environmental Data Science student at the University of California Santa Barbara, studying to apply data science skills to real challenges facing our ever-changing climate.\n\n\nMaster in Environmental Data Science [Present] University of California, Santa Barbara\nBS in Business Administration [2018] University of Vermont\n\n\n\nEntrepreneurship Teaching Assistant [2023 - Present] UCSB\nSolutions Consultant [2021 - 2023] Smartsheet\nAI Solutions Consultant [2018 - 2021] Quinyx"
  },
  {
    "objectID": "index.html#hi-there",
    "href": "index.html#hi-there",
    "title": "Carly Caswell",
    "section": "",
    "text": "My name is Carly and welcome to my personal website. This site will give you an overview of my professional life, interests, and passions (both personal and work-related).\nWhat am I up to right now?\nI am currently a Master of Environmental Data Science student at the University of California Santa Barbara, studying to apply data science skills to real challenges facing our ever-changing climate.\n\n\nMaster in Environmental Data Science [Present] University of California, Santa Barbara\nBS in Business Administration [2018] University of Vermont\n\n\n\nEntrepreneurship Teaching Assistant [2023 - Present] UCSB\nSolutions Consultant [2021 - 2023] Smartsheet\nAI Solutions Consultant [2018 - 2021] Quinyx"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "Analyzing the Implications of Data, Documentation, and Decision-Making in Climate-Driven Artificial Intelligence\n\n\n\nAI\n\n\nEthics\n\n\nClimate\n\n\nMEDS\n\n\n\nA blog for EDS242: Ethics and Bias in Data Science\n\n\n\nCarly Caswell\n\n\nDec 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Santa Barbara County’s Thomas Fire\n\n\n\nPython\n\n\nGIS\n\n\nClimate\n\n\nMEDS\n\n\n\nVisualizing changes in air quality index (AQI). A blog for EDS220: Working with Environmental Datasets\n\n\n\nCarly Caswell\n\n\nDec 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntest blog post title\n\n\n\nQuarto\n\n\nR\n\n\nMEDS\n\n\n\nblog post test description\n\n\n\nCarly Caswell\n\n\nOct 29, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]